# C51提出的动机

传统的基于价值的强化学习算法，如 DQN 使用**平均值**估计**累积折扣回报价值**，不要完了，累积折扣回报是一个苏随机变量，而随机变量是有分布的，这个分布要比均值涵盖的信息多太多了。

值分布（Distribution）强化学习方法显式地对这种价值函数Q-value分布进行建模，而不是仅估计均值。这可以为代理带来更多的洞察力和知识。事实上，结果显示了对价值分布本身进行建模的有用性。导致更快、更稳定的代理学习。

